{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c9709db34bd4106b63e36b397b59fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c7fd3e407c3e4f38afc0fc84e8a84c64",
              "IPY_MODEL_0e44038c77914789a9e7fce233c8720a",
              "IPY_MODEL_ad1c2a28ab3644ae9fbb13f43cf743b4"
            ],
            "layout": "IPY_MODEL_7f15d9c0ba054bf9af636c5d3538ac9c"
          }
        },
        "c7fd3e407c3e4f38afc0fc84e8a84c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b8bf95a59434948b01d5d7c37489ea2",
            "placeholder": "​",
            "style": "IPY_MODEL_4a553e26d2cd41cc8d94be3c28badef9",
            "value": " 81%"
          }
        },
        "0e44038c77914789a9e7fce233c8720a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbf8c9b2eb52437b943698f7ae7592d9",
            "max": 2479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d1d04e9a3049ed9ce01b79430a23a9",
            "value": 2013
          }
        },
        "ad1c2a28ab3644ae9fbb13f43cf743b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee9ca12d3ef46b7a7f265a53ea7b856",
            "placeholder": "​",
            "style": "IPY_MODEL_83b445f87f8946b8ad0cd68f207abc13",
            "value": " 2013/2479 [24:13&lt;05:36,  1.39it/s]"
          }
        },
        "7f15d9c0ba054bf9af636c5d3538ac9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8bf95a59434948b01d5d7c37489ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a553e26d2cd41cc8d94be3c28badef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbf8c9b2eb52437b943698f7ae7592d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d1d04e9a3049ed9ce01b79430a23a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ee9ca12d3ef46b7a7f265a53ea7b856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b445f87f8946b8ad0cd68f207abc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce001b8459e4cd39966d05ecc624925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8748d81259cf4e668b9fdce96bb5ed83",
              "IPY_MODEL_868698d2905b41199813c51b12dc0e93",
              "IPY_MODEL_d810852c05304bcb9661119f8aa3b07b"
            ],
            "layout": "IPY_MODEL_3170092fbbe442a8b3d744e812bb37ba"
          }
        },
        "8748d81259cf4e668b9fdce96bb5ed83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c74955eea21447e94a34968535eb28c",
            "placeholder": "​",
            "style": "IPY_MODEL_c86a17be733f44e5b69b431cc5d9f856",
            "value": "100%"
          }
        },
        "868698d2905b41199813c51b12dc0e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d242ad0ea848958b0743974cadddd8",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6747b6e8a664da6b16fdb15959e83ab",
            "value": 80
          }
        },
        "d810852c05304bcb9661119f8aa3b07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34cbbd38bf24c09b43792e8e2411b3f",
            "placeholder": "​",
            "style": "IPY_MODEL_37b3d2b6677048c7974f901508104602",
            "value": " 80/80 [01:12&lt;00:00,  1.14it/s]"
          }
        },
        "3170092fbbe442a8b3d744e812bb37ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c74955eea21447e94a34968535eb28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86a17be733f44e5b69b431cc5d9f856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d242ad0ea848958b0743974cadddd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6747b6e8a664da6b16fdb15959e83ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d34cbbd38bf24c09b43792e8e2411b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b3d2b6677048c7974f901508104602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Python Script Generation\n",
        "\n",
        "-----\n",
        "\n",
        "### ANLY-580: Natural Language Processing\n",
        "\n",
        "This notebook contains the code required to perform Python script generation as a part of Georgetown University's ANLY-580 Final Project.\n",
        "\n",
        "<br>\n",
        "\n",
        "Authors:\n",
        "* Eduardo Armenta (ea795@georgetown.edu)\n",
        "* Landon Carpenter (lc1276@georgetown.edu)\n",
        "* Matthew Moriarty (mdm341@georgetown.edu)\n",
        "\n",
        "<br>\n",
        "\n",
        "In this notebook, we will use a Generative Pre-Trained Transformer (GPT) model in order to generate Python scripts from given English prompts. An example of this is as follows:\n",
        "\n",
        "```\n",
        "## Input - English Prompt\n",
        "\"write a python function that computes the maximum of three integers\"\n",
        "\n",
        "## Output - Python Script\n",
        "def (num1, num2, num3):\n",
        "  max = num1\n",
        "  if num2 > max:\n",
        "    max = num2\n",
        "  if num3 > max:\n",
        "    max = num3\n",
        "  return max\n",
        "```\n",
        "\n",
        "In order to accomplish this task, we will heavily utilize `Hugging Face` and `PyTorch`. These resources provide libraries such as `transformers` and `torch` that will be very useful to us in accomplishing our task.\n",
        "\n",
        "We will also utilize Google Colab in order to obtain the computations resources required for training our model. Here, we can use GPUs - rather than CPUs - to perform the heavy computational tasks required by our model. As such, it is important to find the `Runtime` tab above, navigate to `Change runtime type`, and select the `GPU` hardware accelerator."
      ],
      "metadata": {
        "id": "1mwFFKudmEHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "In this section, we ensure that our Google Colab environment is equipped with the necessary resources before proceeding with our task.\n",
        "\n",
        "## Installing Necessary Libraries\n",
        "\n",
        "Before we begin building our models and completing our task, we must ensure that we have the necessary libraries installed. Here, we will install the following:\n",
        "\n",
        "* `transformers`: this library allows us to access our GPT2 model, tokenizer, and other resources."
      ],
      "metadata": {
        "id": "d_INAKyQqYBE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0878V6ZFK7ou"
      },
      "outputs": [],
      "source": [
        "# install transformers\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab already has the other libraries that we need installed, such as `torch`, `pandas`, and `numpy`, so we can proceed with importing these libraries into our Python environment.\n",
        "\n",
        "## Importing Necessary Libraries\n",
        "\n",
        "With the required libraries installed on Google Colab, we can import them into our Python environment."
      ],
      "metadata": {
        "id": "0PgiKihXrrvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform necessary imports\n",
        "\n",
        "# data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# huggingface transformer libraries\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel # , do we need these? GPT2Model, GPT2Config, AutoModelWithLMHead\n",
        "from transformers import get_linear_schedule_with_warmup # AdamW\n",
        "\n",
        "# pytorch libraries\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader, random_split#, RandomSampler, SequentialSampler\n",
        "\n",
        "# progress bar for model training\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "### additional imports, not sure if we need these either?\n",
        "# import re, os, sys, time, datetime, nltk, random\n",
        "\n",
        "### we aren't plotting anything are we?\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# from torch.utils.data import Dataset, DataLoader, random_split # , do we need these? RandomSampler, SequentialSampler\n",
        "# torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "7Nx3ygcwLIhD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading the Data\n",
        "\n",
        "In order to access the data that we'd like to use for our Python script generation task, we must upload it to Google Colab in a location that is accessible to us. We will upload our data, contained in the `pythonTextData.txt` file, to the `sample_data/` directory provided by Google Colab."
      ],
      "metadata": {
        "id": "bU9vyckwyThs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the Data\n",
        "\n",
        "In this section, we prepare our data for use in our Python script generation task.\n",
        "\n",
        "## Read in the Data\n",
        "\n",
        "We first must read in the data. As specified in the previous section, we will be reading this data from the following location: `sample_data/pythonTextData.txt`."
      ],
      "metadata": {
        "id": "PVrKfrTD0gBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in the data using a try-catch block for error-handling\n",
        "try:  \n",
        "  with open(\"sample_data/pythonTextData.txt\", \"r\", encoding = \"utf8\") as file:\n",
        "    # read in the file as a list of lines\n",
        "    lines = file.readlines()\n",
        "    # report success and number of lines read in\n",
        "    print('The data has been read in successfully.')\n",
        "    print('The data contains', len(lines), 'lines.')\n",
        "except:\n",
        "  # report failure by raising exception\n",
        "  raise Exception('There was a problem reading in the data.')"
      ],
      "metadata": {
        "id": "1EexIrY0LXh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078b18b8-c0ca-41ce-e6a0-b7c908aa92cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data has been read in successfully.\n",
            "The data contains 42745 lines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the Data\n",
        "\n",
        "We have read in our data, but we need to extract the information we need from it. The first several lines of the data look like the following:\n",
        "\n",
        "```\n",
        "# write a python program to add two numbers\n",
        "num1 = 1.5\n",
        "num2 = 6.3\n",
        "sum = num1 + num2\n",
        "print(f'Sum: {sum}')\n",
        "\n",
        "\n",
        "# write a python function to add two user provided numbers and return the sum\n",
        "def add_two_numbers(num1, num2):\n",
        "    sum = num1 + num2\n",
        "    return sum\n",
        "```\n",
        "\n",
        "As we can see, the data is formatted in such a way that each prompt is on a line of its own and starts with a `#` character, just like a Python in-line comment. Each prompt is then followed by one or more lines that define the Python code that completes the task that the prompt raises. Finally, these code blocks are followed by two empty lines before the next prompt appears. We can utilize this structure in order to extract each prompt and its corresponding Python code block."
      ],
      "metadata": {
        "id": "bTz2cINv3K9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# collect all indices of lines with '#'\n",
        "src_indexes = [i for i, line in enumerate(lines) if line.startswith('#')]\n",
        "# extract all those lines for use in the source column\n",
        "src = [lines[i].lower() for i in src_indexes]\n",
        "\n",
        "# collect all the targets by extracting the lines between the indices of the sources\n",
        "tgt = [''.join(lines[src_indexes[i]+1:src_indexes[i+1]]).lower() for i, value in enumerate(src_indexes[:-1])]\n",
        "# retrieve the last one as it is not captured by the line above\n",
        "tgt.append(''.join(lines[src_indexes[-1]+1:]))\n",
        "\n",
        "# assert that we collected the same number of sources and targets\\n\",\n",
        "assert len(src) == len(tgt), 'The number of sources (prompts) collected does not equal the number of targets (code blocks) collected.'\n",
        "\n",
        "# place source-target pairs into a data frame\n",
        "python_df = pd.DataFrame({'src':src, 'tgt':tgt})\n",
        "\n",
        "# create a new column that is the concatenation of each source-target pair\n",
        "python_df['txt'] = python_df['src'] + ' | ' + python_df['tgt']"
      ],
      "metadata": {
        "id": "eH9bcqNIMuug"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to visually observe what we have done in our preprocessing steps, so let's take a look at the first few rows of the data frame."
      ],
      "metadata": {
        "id": "L8lAMuNd93ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display the first five rows of the data frame\n",
        "python_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0JmEHnaY9_IS",
        "outputId": "dba982b2-5e95-4492-b062-76544eee2de5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 src  \\\n",
              "0     # write a python program to add two numbers \\n   \n",
              "1  # write a python function to add two user prov...   \n",
              "2  # write a program to find and print the larges...   \n",
              "3  # write a program to find and print the smalle...   \n",
              "4  # write a python function to merge two given l...   \n",
              "\n",
              "                                                 tgt  \\\n",
              "0  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...   \n",
              "1  def add_two_numbers(num1, num2):\\n    sum = nu...   \n",
              "2  \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >=...   \n",
              "3  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...   \n",
              "4  def merge_lists(l1, l2):\\n    return l1 + l2\\n...   \n",
              "\n",
              "                                                 txt  \n",
              "0  # write a python program to add two numbers \\n...  \n",
              "1  # write a python function to add two user prov...  \n",
              "2  # write a program to find and print the larges...  \n",
              "3  # write a program to find and print the smalle...  \n",
              "4  # write a python function to merge two given l...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1e7d697-0f6b-437c-8fa5-5f89fe099cb6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tgt</th>\n",
              "      <th>txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "      <td># write a python program to add two numbers \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># write a python function to add two user prov...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "      <td># write a python function to add two user prov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># write a program to find and print the larges...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;=...</td>\n",
              "      <td># write a program to find and print the larges...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># write a program to find and print the smalle...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "      <td># write a program to find and print the smalle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># write a python function to merge two given l...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "      <td># write a python function to merge two given l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1e7d697-0f6b-437c-8fa5-5f89fe099cb6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1e7d697-0f6b-437c-8fa5-5f89fe099cb6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1e7d697-0f6b-437c-8fa5-5f89fe099cb6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct the Model\n",
        "\n",
        "In this section, we will prepare the rest of our resources for our Python script generation task. Here, we will create our model using the `GPT2Tokenizer` and the `GPT2LMHeadModel` from the `transformers` library, create a simple `Dataset` class specific to our task, and utilize the `DataLoader` from the `torch.utils` library in order to provide our data to our model.\n",
        "\n",
        "## Define Hyperparameters\n",
        "\n",
        "We can first define some hyperparameters that we will use throughout this section. These include:\n",
        "\n",
        "* `bsize`: the batch size to use when batching data\n",
        "* `epochs`: the number of epochs to use in training\n",
        "* `lr_init`: the initial rate by which the model learns\n",
        "* `warmup_steps`: the number of steps to take during training before utilizing the initialized learning rate\n",
        "\n",
        "Note that we will use a very small batch size (`bsize = 4`) in order to preserve memory on Google Colab's GPU.\n"
      ],
      "metadata": {
        "id": "IPGPiA4U-Yic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyperparameters\n",
        "bsize = 2\n",
        "epochs = 5\n",
        "lr_init = 1e-5\n",
        "warmup_steps = 100"
      ],
      "metadata": {
        "id": "XpMU10uzTnOg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Tokenizer\n",
        "\n",
        "We will retrieve our tokenizer using the pretrained `distilgpt2` option provided by Hugging Face."
      ],
      "metadata": {
        "id": "mJ1df9ugTnwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token='<SOS>', eos_token='<EOS>', pad_token='<PAD>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVs-k9WY_cZI",
        "outputId": "990c0775-8b59-4a91-9d82-7fc3d35cc33e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Dataset\n",
        "\n",
        "We will use `torch.utils.data`'s `Dataset` and `DataLoader` features in order to construct our dataset in such a way that is compatible with our model (<a href=\"https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\">PyTorch: Datasets & DataLoaders</a>).\n",
        "\n",
        "First, we will create a class `Python_Dataset` using `torch.utils.data`'s `Dataset`."
      ],
      "metadata": {
        "id": "o9UCWvQID4kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Python_Dataset' class for our python text data\n",
        "class Python_Dataset(Dataset):\n",
        "\n",
        "  # we need an __init__ function\n",
        "  def __init__(self, input_txt, input_tokenizer):# do we need these?, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    # store the incoming tokenizer as an attribute of the instance\n",
        "    self.tokenizer = input_tokenizer\n",
        "    # create attributes to store input IDs and attention masks\n",
        "    self.input_ids_list = []; self.attention_mask_list = []\n",
        "\n",
        "    # iterate through each source-target pair\n",
        "    for txt in input_txt:\n",
        "      # encode the text using special tokens defined above\n",
        "      encodings_dict = input_tokenizer('<SOS>'+ txt + '<EOS>', truncation = True, padding = \"max_length\") # , max_length = max_length)\n",
        "      # store the encoded input IDs and attention mask as tensors\n",
        "      input_ids = torch.tensor(encodings_dict['input_ids'])\n",
        "      attention_mask = torch.tensor(encodings_dict['attention_mask'])\n",
        "      # append the input IDs and attention mask to the class attribute lists\n",
        "      self.input_ids_list.append(input_ids)\n",
        "      self.attention_mask_list.append(attention_mask)\n",
        "\n",
        "  # we need a __len__ function \n",
        "  def __len__(self):\n",
        "    # return the number of lists of input IDs gathered (should match number of texts)\n",
        "    return len(self.input_ids_list)\n",
        "\n",
        "  # we need a __getitem__ function\n",
        "  def __getitem__(self, idx):\n",
        "    # return a tuple of the input IDs and attention mask for the current item\n",
        "    return self.input_ids_list[idx], self.attention_mask_list[idx] "
      ],
      "metadata": {
        "id": "J_WVwTO3NAjw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will create an instance of the `Python_Dataset` class using the class constructor and the data frame that we stored our data in, `python_df`."
      ],
      "metadata": {
        "id": "vCO7SAn_JgUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create instance of Python_Dataset class\n",
        "python_dataset = Python_Dataset(python_df['txt'], tokenizer)#, max_length=768)"
      ],
      "metadata": {
        "id": "ZK_EqIlVL9bb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then split our data into training and testing sets, using a random 80%-20% split. We can continue to utilize `torch.utils.data` here and use the `random_split` function for this. We should also check our result to ensure that the split is made correctly. We can print the length of each resulting partition in order to ensure this. With 4,958 source-target pairs, we can expect to see approximately **3,966** observations in our training dataset and the remaining **992** in our testing dataset."
      ],
      "metadata": {
        "id": "630qq_GJNj-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform an 80/20 split of the data for training/testing\n",
        "# train_len = int(0.80 * len(python_dataset))\n",
        "# test_len = len(python_dataset) - train_len\n",
        "# train_data, test_data = random_split(python_dataset, [train_len, test_len])\n",
        "\n",
        "# report the number of observations for both training and testing\n",
        "print('Number of training observations:', len(python_dataset)) ###\n",
        "# print('Number of testing observations:', len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPGB0o2kNjj9",
        "outputId": "697d4bbb-36ad-477a-c48f-74ef4ed4fa59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training observations: 4958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can wrap an *iterable* around our dataset using `torch.utils.data`'s `DataLoader`. According to documentation for this feature, wrapping an iterable around the dataset allows the observations within the dataset to be more easily accessed.\n",
        "\n",
        "We can once again ensure that our data has been loaded properly by observing the lengths of our DataLoader objects. Using a batch size of 16, we can expect the training DataLoader to have ceil($\\frac{3966}{16}$)= **248** batches. Similarly, we can expect the testing DataLoader to have ceil($\\frac{992}{16}$)= **62** batches."
      ],
      "metadata": {
        "id": "Xm1wLBtaOgpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the data loader for both training and testing\n",
        "# train_batches = DataLoader(train_data, batch_size = bsize)#, # sampler = RandomSampler(train_dataset),)\n",
        "# test_batches = DataLoader(test_data, batch_size = bsize)#, # sampler = SequentialSampler(val_dataset),)\n",
        "\n",
        "all_batches = DataLoader(python_dataset, batch_size = bsize)\n",
        "\n",
        "# report the number of loaded batches for both training and testing\n",
        "print('Number of training batches:', len(all_batches))\n",
        "# print('Number of testing batches:', len(test_batches))"
      ],
      "metadata": {
        "id": "cSApjXjQNGET",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d535ff-b4c4-4de6-ba1b-2a55ce017ca1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches: 2479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Model\n",
        "\n",
        "We will use `transformers`' `GPT2LMHeadModel` here in order to retrieve our model. Using the `distilgpt2` option as we used with the tokenizer, we can retrieve a smaller, more manageable version of GPT2."
      ],
      "metadata": {
        "id": "CQn7uGxIRUwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model using distilgpt2\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")#, config=configuration)\n",
        "\n",
        "model.resize_token_embeddings(len(tokenizer));"
      ],
      "metadata": {
        "id": "JI_h90KLSOEb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our model will require strong computational resources, we could place the model directly on Google Colab's GPU, but we opt for a safer way of doing so. Below, we only place the model on the GPU if it is available."
      ],
      "metadata": {
        "id": "w53Q8AJXSoyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# send the model to the available device\n",
        "if torch.cuda.is_available():\n",
        "  # if available, use GPU\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  # otherwise, use CPU\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "# push the model to the selected device\n",
        "model.to(device);\n",
        "\n",
        "# report the device that the model was pushed to\n",
        "print('The model has been pushed to device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAqaKfmWS3PT",
        "outputId": "98ef2a25-a757-47ec-96bf-6b2e68554d7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has been pushed to device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also initialize our optimizer and create a scheduled learning rate. These components will allow our model to learn in a more constructive way, rather than a more erratic one."
      ],
      "metadata": {
        "id": "bmnrd_10TDnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = lr_init)\n",
        "\n",
        "# initialize a scheduled learning rate\n",
        "lr = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps = warmup_steps, \n",
        "    num_training_steps = len(all_batches)) # train_batches"
      ],
      "metadata": {
        "id": "wh4A4Y33TIG6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "\n",
        "In this section, we train our model using all the features that we have organized. We define a function, `runner`, to execute the training process and call the function using our training data."
      ],
      "metadata": {
        "id": "BsiuhPI4TIxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def runner(batches):\n",
        "\n",
        "  # prepare for training\n",
        "  model.train()\n",
        "\n",
        "  # train the model over the number of specified epochs\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # start a progress bar, which will help for observing runtime\n",
        "    print('Training: Epoch', epoch + 1)\n",
        "    progress_bar = tqdm(range(len(batches)))\n",
        "\n",
        "    # iterate through all batches\n",
        "    for batch in batches:\n",
        "\n",
        "      # extract the input IDs (position 0)\n",
        "      input_ids = batch[0].to(device)\n",
        "      labels = batch[0].to(device)\n",
        "      # extract the attention masks (position 1)\n",
        "      attention_masks = batch[1].to(device)       \n",
        "\n",
        "      # retrieve the outputs of the model\n",
        "      outputs = model(input_ids,\n",
        "                      labels = labels, \n",
        "                      attention_mask = attention_masks,\n",
        "                        # token_type_ids=None\n",
        "                     ) \n",
        "\n",
        "      # compute loss and backpropogate\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      # advance the optimizer and learning rates\n",
        "      optimizer.step()\n",
        "      lr.step()\n",
        "      # zero out gradients so they won't affect the next batch\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # update the progress bar\n",
        "      progress_bar.update(1)"
      ],
      "metadata": {
        "id": "M_Mr3BYZiibt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model using the function above\n",
        "runner(all_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "7c9709db34bd4106b63e36b397b59fbc",
            "c7fd3e407c3e4f38afc0fc84e8a84c64",
            "0e44038c77914789a9e7fce233c8720a",
            "ad1c2a28ab3644ae9fbb13f43cf743b4",
            "7f15d9c0ba054bf9af636c5d3538ac9c",
            "2b8bf95a59434948b01d5d7c37489ea2",
            "4a553e26d2cd41cc8d94be3c28badef9",
            "fbf8c9b2eb52437b943698f7ae7592d9",
            "25d1d04e9a3049ed9ce01b79430a23a9",
            "0ee9ca12d3ef46b7a7f265a53ea7b856",
            "83b445f87f8946b8ad0cd68f207abc13"
          ]
        },
        "id": "y-jSBUHGpS_B",
        "outputId": "e2d1be70-46bf-40ac-8891-495277e1711e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: Epoch 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2479 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c9709db34bd4106b63e36b397b59fbc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MATT ADAPTATION\n",
        "\n",
        "# total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# model = model.to(device)\n",
        "\n",
        "# start a progress bar, which will help for observing runtime\n",
        "progress_bar = tqdm(range(len(train_batches)*epochs))\n",
        "\n",
        "# prepare for training\n",
        "model.train()\n",
        "\n",
        "# for epoch_i in range(0, epochs):\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # print(\"\")\n",
        "    # print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    # print('Training...')\n",
        "\n",
        "    # t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # for step, batch in enumerate(train_dataloader):\n",
        "    for batch in train_batches:\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)       \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels = b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids = None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        # if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "        #     elapsed = format_time(time.time() - t0)\n",
        "        #     print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "        #     model.eval()\n",
        "\n",
        "        #     sample_outputs = model.generate(\n",
        "        #                             bos_token_id=random.randint(1,30000),\n",
        "        #                             do_sample=True,   \n",
        "        #                             top_k=50, \n",
        "        #                             max_length = 200,\n",
        "        #                             top_p=0.95, \n",
        "        #                             num_return_sequences=1\n",
        "        #                         )\n",
        "        #     for i, sample_output in enumerate(sample_outputs):\n",
        "        #           print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "        #     model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        lr.step()\n",
        "\n",
        "        model.zero_grad() \n",
        "\n",
        "        # update the progress bar\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_batches)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    # training_time = format_time(time.time() - t0)\n",
        "\n",
        "    # print(\"\")\n",
        "    # print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    # print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "\n",
        "##########\n",
        "\n",
        "\n",
        "#     print(\"\")\n",
        "#     print(\"Running Validation...\")\n",
        "\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     model.eval()\n",
        "\n",
        "#     total_eval_loss = 0\n",
        "#     nb_eval_steps = 0\n",
        "\n",
        "#     # Evaluate data for one epoch\n",
        "#     for batch in validation_dataloader:\n",
        "        \n",
        "#         b_input_ids = batch[0].to(device)\n",
        "#         b_labels = batch[0].to(device)\n",
        "#         b_masks = batch[1].to(device)\n",
        "        \n",
        "#         with torch.no_grad():        \n",
        "\n",
        "#             outputs  = model(b_input_ids, \n",
        "# #                            token_type_ids=None, \n",
        "#                              attention_mask = b_masks,\n",
        "#                             labels=b_labels)\n",
        "          \n",
        "#             loss = outputs[0]  \n",
        "            \n",
        "#         batch_loss = loss.item()\n",
        "#         total_eval_loss += batch_loss        \n",
        "\n",
        "#     avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "#     validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "#     print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "#     print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "#     # Record all statistics from this epoch.\n",
        "#     training_stats.append(\n",
        "#         {\n",
        "#             'epoch': epoch_i + 1,\n",
        "#             'Training Loss': avg_train_loss,\n",
        "#             'Valid. Loss': avg_val_loss,\n",
        "#             'Training Time': training_time,\n",
        "#             'Validation Time': validation_time\n",
        "#         }\n",
        "#     )\n",
        "\n",
        "\n",
        "##########\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "# print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5ce001b8459e4cd39966d05ecc624925",
            "8748d81259cf4e668b9fdce96bb5ed83",
            "868698d2905b41199813c51b12dc0e93",
            "d810852c05304bcb9661119f8aa3b07b",
            "3170092fbbe442a8b3d744e812bb37ba",
            "1c74955eea21447e94a34968535eb28c",
            "c86a17be733f44e5b69b431cc5d9f856",
            "d7d242ad0ea848958b0743974cadddd8",
            "b6747b6e8a664da6b16fdb15959e83ab",
            "d34cbbd38bf24c09b43792e8e2411b3f",
            "37b3d2b6677048c7974f901508104602"
          ]
        },
        "id": "hndys0xUWGR0",
        "outputId": "1743281d-c5ea-40c0-a5cc-7a3499691fc3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ce001b8459e4cd39966d05ecc624925"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### OLD VERSION\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels, \n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]  \n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,   \n",
        "                                    top_k=50, \n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95, \n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs  = model(b_input_ids, \n",
        "#                            token_type_ids=None, \n",
        "                             attention_mask = b_masks,\n",
        "                            labels=b_labels)\n",
        "          \n",
        "            loss = outputs[0]  \n",
        "            \n",
        "        batch_loss = loss.item()\n",
        "        total_eval_loss += batch_loss        \n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)    \n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrzGe4cXOocE",
        "outputId": "56316e2c-142b-4f1a-a266-fdaa0196278b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  2,231. Loss: 0.30973324179649353.   Elapsed: 0:00:50.\n",
            "0:  bipartisan,\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  2,231. Loss: 0.16636155545711517.   Elapsed: 0:01:43.\n",
            "0:  increasing# write a python function to extract name from string\n",
            " | \n",
            "print(\"input string: \"))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  2,231. Loss: 0.253745973110199.   Elapsed: 0:02:33.\n",
            "0: day# write a python program to print the total count\n",
            " | import count\n",
            "def total_count ( count, values = [])\n",
            "count = count * values\n",
            "print(count, total_count, values)\n",
            "print(count)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  2,231. Loss: 0.13521066308021545.   Elapsed: 0:03:24.\n",
            "0:  Hang# write a function that takes a dict.get a dictionary and returns the same value\n",
            " | def dict(dict1, dict2):\n",
            "    return dict1\n",
            "  def dict2(dict1, dict2):\n",
            "     return dict1\n",
            "\n",
            "\n",
            "def set_dict(dict1, dict2):\n",
            "       return (dict2[1:] + dict1[2:])\n",
            "\n",
            "\n",
            "def add(dict1):\n",
            "       print(dict2.get(dict1, dict2))\n",
            "\n",
            "     return (dict1.get(dict2, dict2) + dict2)\n",
            "\n",
            "    else:\n",
            "       print(dict1)\n",
            "\n",
            "\n",
            "def add(dict2):\n",
            "     return dict1\n",
            "\n",
            "    return(dict2)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  2,231. Loss: 0.23476506769657135.   Elapsed: 0:04:16.\n",
            "0:  foods# write a function to return whether a file is composed of multiple words\n",
            " | \n",
            "def   writea(file1, file2):\n",
            "       return file1[0] + file2[1]\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  2,231. Loss: 0.32761454582214355.   Elapsed: 0:05:06.\n",
            "0:  trail# write a function to return the maximum frequency of a given string by recursion\n",
            " | def get_maximum_fahrenheit_from_string(string):\n",
            "   if not string:\n",
            "    return \"max_fahrenheit_ from string\"\n",
            "print(\"best\" * {5}\").format(string.length())\n",
            "else:\n",
            "   print(\"the highest {5}\")\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  2,231. Loss: 0.9197306632995605.   Elapsed: 0:05:57.\n",
            "0: intend# write a python function to check if element is a palindrome\n",
            " | def palindrome(e:string):\n",
            "    return e[::2]\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  2,231. Loss: 0.0569000281393528.   Elapsed: 0:06:48.\n",
            "0:  surround# write a python program to find the area of a square root of the area of a cube with given area and cube height  \n",
            " |  def cal_area_square_radius(radius,height):  \n",
            "      return (radius**3)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  2,231. Loss: 0.14406147599220276.   Elapsed: 0:07:38.\n",
            "0:  reflex# write a function that will return the area of the area of a circle\n",
            " | def cal_areaarea(area, area_area):\n",
            "   return (area * 1 ** 8)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  2,231. Loss: 0.19377556443214417.   Elapsed: 0:08:29.\n",
            "0:  display# initializing python program\n",
            " | import time\n",
            "n = time.days(len(tup(tup))\n",
            "print(\"after initializing tuple list: \")\n",
            "print (\"initizing tuple list : \"))\n",
            "print (f'total tuple after initializing tuple list: \", str.upper())\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  2,231. Loss: 0.07458175718784332.   Elapsed: 0:09:19.\n",
            "0:  pastor# write a python program which returns n as an even number\n",
            " | nums = 0\n",
            "while nums >= 0:\n",
            "   if nums >= 0:\n",
            "       nums -= 1\n",
            "    else:\n",
            "       nums -= 1\n",
            "print (\"the nums of\", nums, nums)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  2,231. Loss: 0.1981954127550125.   Elapsed: 0:10:10.\n",
            "0:  illicit# please write a python program to sort a list\n",
            " | \n",
            "def sort_alist(list):\n",
            "       if list:\n",
            "                     return [list.filter(len(list)) for list in list)]\n",
            "\n",
            "                                                                                                                                   \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  2,231. Loss: 0.22336742281913757.   Elapsed: 0:11:01.\n",
            "0:  Liberation# write a program to create string values by string\n",
            " | str1 = str1.decode('best')\n",
            "print(\"the powerof\", str1)\n",
            "if not str1.decode('best')\n",
            "print(\"the powerof\", str1)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  2,231. Loss: 0.09697529673576355.   Elapsed: 0:11:51.\n",
            "0:  Nam# write a python function to find the odd length in the length of a string and print it  \n",
            " |    \n",
            "def odd_length(my_string):    \n",
            "      \n",
            "    return my_string + my_string     \n",
            "\n",
            "temp = [ele for ele in my_string]  \n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  2,231. Loss: 0.11951907724142075.   Elapsed: 0:12:41.\n",
            "0: ION# write python code to calculate total weighted average of three sublist\n",
            " | \n",
            "def weighted_average(lists): \n",
            "    return total weighted average(lists[:3])\n",
            " \n",
            "print(\"average weighted average of three sublists:\")  \n",
            "\n",
            "    return sum(weights(lists[:5:])\n",
            "  \n",
            "print(f'{sum(weights(lists[:5:])} is {sum(weights(lists[:5:])}')\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  2,231. Loss: 0.12280315160751343.   Elapsed: 0:13:31.\n",
            "0:  glimpse# write a python function to print the first n unique list in a dictionary with unique dictionary value.\n",
            " | def unique_list_with_id_key():\n",
            "     unique_list_with_id_value(dst, {id=st.get(id()))}, {id=lst.get(id()))}')\n",
            "\n",
            "dst.__init__(id_key=unique_list_with_id_key(), names={names}')\n",
            "\n",
            "\n",
            "dst.res.dst_items()\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  2,231. Loss: 0.16331501305103302.   Elapsed: 0:14:22.\n",
            "0:  Laure# write a python function to calculate the lcm on a number\n",
            " | def calc_lcm(n):\n",
            "     return 2x(n-1) + 2x(n-2)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  2,231. Loss: 0.04992960765957832.   Elapsed: 0:15:11.\n",
            "0: ism# write a python function that takes a string and sorts it by the second letter\n",
            " | def reverse_sentence(s = 'u', 'i', 'j','s', 'u']\n",
            "   return sorted(sorted(s.intersection(''))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  2,231. Loss: 0.2102832794189453.   Elapsed: 0:16:01.\n",
            "0: oun# write a python function to return the product of an interval using all else\n",
            " | \n",
            "def productintervals(interval):\n",
            "   if interval >= 1:\n",
            "       greaterintervals(interval),\n",
            "       greater(interval-1),\n",
            "       greater(interval-1),\n",
            "         greater(interval-1),\n",
            "          greater(interval-1),\n",
            "           greater(interval-1),\n",
            "              greater(interval-1),\n",
            "           greater(interval-1),\n",
            "           greater(interval-1),\n",
            "             \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  2,231. Loss: 0.09303796291351318.   Elapsed: 0:16:53.\n",
            "0:  election# write a python program to remove the punctuations from a string\n",
            " | \n",
            "\n",
            "  \n",
            "test_str = \"hello world\"\n",
            "print(\"the original string is : \" + str(test_str))\n",
            "print(\"the remainder of test_str is : \" + str(test_str))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  2,231. Loss: 0.1659221202135086.   Elapsed: 0:17:42.\n",
            "0:  crazy# write python program to create a dictionary that has all the values of each pair, as a list.\n",
            " | dict1 = {1: 5, 7: 7, 8: 7, 9: 7}\n",
            "\n",
            "dict2 = {6: 7, 7: 7, 8: 7}\n",
            "print(\"dict1:{dict2)}\")\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  2,231. Loss: 0.14148211479187012.   Elapsed: 0:18:32.\n",
            "0:  bench# write a program to remove spaces from a list and print the new list\n",
            " | l = []\n",
            "for x in li:\n",
            "   s = l[:-1]\n",
            "    if x.islower():\n",
            "       new_l = new_list\n",
            "print(\"remove spaces from a list and print list: \", new_l)\n",
            "\n",
            "\n",
            "\n",
            "  Average training loss: 0.26\n",
            "  Training epoch took: 0:18:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:39\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  2,231. Loss: 0.05213026702404022.   Elapsed: 0:00:49.\n",
            "0:  incorporated# write a python program to extract all words from a given file\n",
            " | from random import re\n",
            "\n",
            "print(re.findall('r')[:5])\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  2,231. Loss: 0.12873883545398712.   Elapsed: 0:01:39.\n",
            "0: Peter#32. python program to multiply two numbers and display it\n",
            " | num1 = 823\n",
            "num2 = 834\n",
            "num3 = 6\n",
            "num4 = 1\n",
            "sum = num1 + num2 + num3\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  2,231. Loss: 0.18198241293430328.   Elapsed: 0:02:29.\n",
            "0: uring# write python code to replace odd element in dictionary with \" \", to remove empty dictionaries\n",
            " | mydict = {'odd': 1, 2, 3, 4} \n",
            " \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  2,231. Loss: 0.061430029571056366.   Elapsed: 0:03:18.\n",
            "0:  reproductive# write a python program to print the number of odd elements in a list of integers and the sum of the odd elements. print the sum\n",
            " | li = [11, 2, 5, 3, 5]\n",
            "odd_nosums = li[0]\n",
            "print(odd_nosums)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  2,231. Loss: 0.06915110349655151.   Elapsed: 0:04:08.\n",
            "0:  zone# write a python function to check if a number is prime or not\n",
            " | def check_prime(n):\n",
            "   if n == 1:\n",
            "      if n == 2:\n",
            "         return n\n",
            "\t\n",
            "\telse:\n",
            "          return n\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  2,231. Loss: 0.14304013550281525.   Elapsed: 0:04:58.\n",
            "0:  commits# define a function which can generate a string where the first and last character is the first and last character is the last character. the function needs to print the first and last character\n",
            " | def print_last_char(string):\n",
            "    if not isinstance(string):\n",
            "        print(\"\".join(set(string))\n",
            "     else:\n",
            "          print(\" \".join(set(string)))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  2,231. Loss: 0.13509559631347656.   Elapsed: 0:05:48.\n",
            "0:  irony# write a program to remove tuples whose length is less than given length from a list of tuples.\n",
            " | tuplex = [('a', 'b', 'c'), ('a', 'b', 'c'), ('a', 'c'), ('a', 'b'), ('b', 'c'), (a, 'b', 'c'), (b, 'c'), (a, 'c'), (a, 'c'), (b, 'c'), (c, 'a'), (b, 'c'), (a, 'b'), (b, 'c'), (a, 'a'), (b, 'c'), (b, 'c'), (a, 'b'), (a, 'c')]\n",
            "print(x_to_be_sent)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  2,231. Loss: 0.11015886813402176.   Elapsed: 0:06:39.\n",
            "0:  Sah# write a python function to calculate simple interest\n",
            " | def simple_interest(lst): \n",
            "    si = 12 \n",
            "    for i in range(0, lst - 1): \n",
            "       si += (i * 10 + 1)/100 * si \n",
            "         for i in range(0, 10):  \n",
            "           si += (i - 1)/100 - 1 \n",
            "     return si  \n",
            "    \n",
            "     \n",
            "          \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  2,231. Loss: 0.25705328583717346.   Elapsed: 0:07:30.\n",
            "0:  Bryan# write a function that returns the sum of the roots of a quadratic equation ax**2 + bx + c = 0\n",
            " | def cal_roots(a:float,b:float,c:float):\n",
            "    return 2*2+b+c*(a**2+b**2)/100\n",
            "def roots_of_n_qad_eq(n):\n",
            "    if (n == 0) and (n == 0): return none\n",
            "    return roots_of_n_qad_eq(n-1,n+2)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  2,231. Loss: 0.08756963163614273.   Elapsed: 0:08:21.\n",
            "0:  spirits# write a python program to print the number of zeros in a list\n",
            " | def zeros(l1, l2):\n",
            "    print(l1)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  2,231. Loss: 0.25399166345596313.   Elapsed: 0:09:11.\n",
            "0:  sees# write a python program that sorts words in a sentence and prints the words' end in a comma-separated sequence\n",
            " | words = sentence.split() \n",
            "print(word.lower() - 1)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  2,231. Loss: 0.04898485541343689.   Elapsed: 0:10:00.\n",
            "0:  hungry# write a function to count number of spaces in a string\n",
            " | \n",
            "def count_spaces(str1, str2):\n",
            "    if len(str1) % 2 == 0:\n",
            "        count += 1\n",
            "   else:\n",
            "          count += 1\n",
            "\n",
            "   def count_spaces(str1, str2):\n",
            "          if str1[0] <= ''.join(str2) and str1[1] <=''.join(str1) and str2[2] <=''.join(str2) and str1[2] <=''.join(str2) and str2[2] <=''.join(str1) and str2[2] <=''.join(str2) and str1[2] <=''.join(str2) and str2[\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  2,231. Loss: 0.05550263822078705.   Elapsed: 0:10:51.\n",
            "0:  PT# write a python program to check if a tuple is symmetrical and print it if symmetry is valid\n",
            " | \n",
            "def symmetry_check(tup, tup):\n",
            "     from bisect import bisect_left   \n",
            "    yy = bisect_left(tup)  \n",
            "    for i in range(x):  \n",
            "        if (tup[tup[i] > tup[0] + 1]): \n",
            "             yy.update(i) \n",
            "     return yy\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  2,231. Loss: 0.08088714629411697.   Elapsed: 0:11:42.\n",
            "0: ü# printing result \n",
            " | print(\"incremented elements : \" + str(res))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  2,231. Loss: 0.13483095169067383.   Elapsed: 0:12:32.\n",
            "0: ruce# check if string is camelcase using try catch\n",
            " | word = '''this assignment assignment assignment is of 900 marks. marks.total marks.\n",
            " | ctr = (word, ctr)\n",
            "if ctr.isupper() and ctr.find('a', 'c'),word.lower() or ctr.find('a', 'c') or ctr.find('a', 'c') or ctr.find('a'):\n",
            "    ctr.update({1:1:1, 2:3, 3:4}')\n",
            "else:\n",
            "   ctr.replace('a', 'a', 'c')\n",
            "   return ctr.replace('a', 'c', 'c')\n",
            "  \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  2,231. Loss: 0.20598001778125763.   Elapsed: 0:13:22.\n",
            "0:  derivatives# write a python program to remove punctuations from an input string and print it\n",
            " | punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
            "for n in punctuations:\n",
            "   print(n)\n",
            "\n",
            "i=0\n",
            "while i<=0:\n",
            "   i+=1\n",
            "   n+=1\n",
            "while i<=n:\n",
            "    print(i)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  2,231. Loss: 0.09815408289432526.   Elapsed: 0:14:13.\n",
            "0: \u0019# write a python function to check a given input strings is unique from a given string  \n",
            " |   \n",
            "def countlist_unique(sentence):    \n",
            "     count = 0\n",
            "   \n",
            "    return len(list(int(list(str(count)))))                                                                                                                                   \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  2,231. Loss: 0.1071963757276535.   Elapsed: 0:15:04.\n",
            "0:  remembering#write a python function that counts the number of spaces in a string\n",
            " | def count_space(str1):\n",
            "    return str1.count(''.join(' '))\n",
            "\n",
            "\n",
            "print(\"the number of spaces in a string are: \", count_space(str1))\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  2,231. Loss: 0.26972097158432007.   Elapsed: 0:15:54.\n",
            "0:  Sources# write a program to calculate and print the length of a dict, whose keys are numbers from 1 to 9 (both included).\n",
            " | import dict\n",
            "dict = dict()\n",
            "dict_length = dict()\n",
            "print(\"dict length : :                                                                                                                                                      \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  2,231. Loss: 0.25765496492385864.   Elapsed: 0:16:45.\n",
            "0: ems# write a python program to check a string is palindrome or not\n",
            " | \n",
            "test_str = \"gfg is best\"\n",
            "  \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  2,231. Loss: 0.11270835250616074.   Elapsed: 0:17:35.\n",
            "0: tz# write a python program to extract digits from tuple list of string and print it\n",
            " | \n",
            "test_list = [(1,3), (3,2), (3,3), (3,3)] \n",
            "print(\"original list : \" + str(test_list)) \n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  2,231. Loss: 0.11840007454156876.   Elapsed: 0:18:25.\n",
            "0: matic# write a python function to convert decimal to binary\n",
            " | def binary_to_dict(n):\n",
            "    return f\"constructed decimal number: {n}\".format(n,n)\n",
            "\n",
            "\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epoch took: 0:18:40\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:00:39\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  2,231. Loss: 0.03384293615818024.   Elapsed: 0:00:49.\n",
            "0:  synd# 3x5 matrix\n",
            " | y = [[1,2,3],[4,5,6],[7,8]]\n",
            "result = [[0 for col in range(len(mat):]) for col in range(len(mat[0])]\n",
            "print(result)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  2,231. Loss: 0.13256137073040009.   Elapsed: 0:01:39.\n",
            "0:  gam# write a python function to find whether a positive integer is negative, negative, zero or even\n",
            " | def check_negative_even(n, val):\n",
            "    if n % 2 == 0:\n",
            "         return 2 ** 1 \n",
            "    else:\n",
            "       print(\"positive integer\")\n",
            "    return -bool(n // 2 )\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  2,231. Loss: 0.060016799718141556.   Elapsed: 0:02:29.\n",
            "0:  injury# write a program to check and print the number of spaces in a string provided by the user\n",
            " | \n",
            "def check_space(str1, str2):\n",
            "     if str1[-1] == str2[1]:\n",
            "         return str1[-1]\n",
            "    else:\n",
            "         return str1[-1]\n",
            "\n",
            "\n",
            "str1 = \"abc4234afde\"\n",
            "\n",
            "print(check_space(str2))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  2,231. Loss: 0.0880725160241127.   Elapsed: 0:03:20.\n",
            "0: aza# write a program to multiply two matrix and print the result. \n",
            " | \n",
            "def multiply_matrix(mat):\n",
            "    # initialize result\n",
            "    # initialize result\n",
            "    # for each element in the matrix\n",
            "    # initialize result\n",
            "    result = [[0 for col in range(mat)] for col in range(mat)] \n",
            "    for each element in the matrix\n",
            "     result.append((col in range(mat)]  \n",
            "    return result \n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  2,231. Loss: 0.11069986969232559.   Elapsed: 0:04:10.\n",
            "0:  membrane# write a python function to find sum of all odd numbers from 0 to 9 and other parameters should include the user provided real numbers and the given real numbers  \n",
            " | def sum_of_all_odd(n):\n",
            "     sum_of_all_odd = 0\n",
            "    for i in range(0, 11):\n",
            "         sum_of_all_odd += i\n",
            "    return sum_of_all_odd\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  2,231. Loss: 0.07291994988918304.   Elapsed: 0:05:00.\n",
            "0: ijing# given a python list, remove all occurrence of the first element and revert\n",
            " | list1 = [5, 20, 30]\n",
            "samplelist = [list1, samplelist for samplelist in samplelist]\n",
            "print(samplelist)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  2,231. Loss: 0.07325958460569382.   Elapsed: 0:05:50.\n",
            "0:  cast# write a python function to find time for a given angle.\n",
            " | def calcangle(hh, mm):\n",
            "    hour_angle = abs(hour_angle - minute) + minute\n",
            "    minute_angle = min(hour_angle, minute) + minute\n",
            "    angle = abs(hour_angle - minute - minute) + minute\n",
            "    angle = min(hour_angle, minute - minute) + minute\n",
            "    angle = min(hour_angle, minute - minute) + minute\n",
            "    angle = min(hour_angle, minute - minute) + minute\n",
            "   angle = min(hour_angle, minute - minute) + minute\n",
            "    angle = abs(hour_angle, minute - minute) + minute\n",
            "    angle = min(hour_angle, minute - minute)) + minute\n",
            "    angle = min(hour_angle, minute - minute\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  2,231. Loss: 0.0757737085223198.   Elapsed: 0:06:41.\n",
            "0:  purch# write a program to accept text and print the words and the characters that will determine if the upper case letter exists in the first 4 characters of a string\n",
            " | word = input(\"upper case letters:\")\n",
            "if word == \"upper case\" or word == \"upper case\":\n",
            "word = \"upper case\"\n",
            "print(word)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  2,231. Loss: 0.06926725059747696.   Elapsed: 0:07:31.\n",
            "0:  shoulders# convert decimal to binary\n",
            " | dec = 344\n",
            "binaryval = 'decimal'\n",
            "binaryval = 'binaryval[::-1]\\w+'\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  2,231. Loss: 0.06641462445259094.   Elapsed: 0:08:21.\n",
            "0:  built# initializing k \n",
            " | k = 10\n",
            "t = 9\n",
            "t = 0\n",
            " \n",
            "  \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  2,231. Loss: 0.11594859510660172.   Elapsed: 0:09:10.\n",
            "0:  openly# write a program to swap variable\n",
            " | a, b = 10\n",
            "a, b = 10\n",
            "print(a, b)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  2,231. Loss: 0.25126662850379944.   Elapsed: 0:10:00.\n",
            "0:  halted# write a python function to convert a dictionary value list to string and print the new list\n",
            " | def dict_to_string(d):\n",
            "    test_list = [{'end program' : (end + 1),    'is' : (int(d.values())}, {'best' : (int(d.values())}]\n",
            "    return list(test_list)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  2,231. Loss: 0.09477080404758453.   Elapsed: 0:10:50.\n",
            "0:  Nik# write a python function to find the area of a rectangle.\n",
            " | \n",
            "def rectangle_area(width, height):\n",
            "     return 2*(width+ height**2)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  2,231. Loss: 0.05494183674454689.   Elapsed: 0:11:40.\n",
            "0:  tin# write a function to calculate area of a cylinder\n",
            " | def cal_area_cylinder(height, radius):\n",
            "   pi=3.14\n",
            "   return 2*pi*radius\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  2,231. Loss: 0.09957006573677063.   Elapsed: 0:12:30.\n",
            "0:  clinical# printing original tuples \n",
            " | print(\"the original tuple 1 : \" + str(test_tup1)) \n",
            "      \n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  2,231. Loss: 0.1481553167104721.   Elapsed: 0:13:19.\n",
            "0: lections# write a python program to check a dictionary value is present in a dictionary and print it\n",
            " | \n",
            "def check_dict(input_dict):\n",
            "     return list(input_dict.get(value)=={\"a\": 1, \"b\": 2, \"c\": 3},  \n",
            "               {\"d\": 'a'}, \n",
            "                {\"f\": \"f\" }\n",
            "  \n",
            "   return true\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  2,231. Loss: 0.02850925922393799.   Elapsed: 0:14:10.\n",
            "0: els# driver code in python\n",
            " | def driver(n):\n",
            "    if n == 0:\n",
            "        return 0\n",
            "     else:\n",
            "          return n + 1\n",
            "\t\t\n",
            "\t\t\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  2,231. Loss: 0.051676370203495026.   Elapsed: 0:15:00.\n",
            "0: lab#write a python program to print the number of letters and digits of a given string\n",
            " | \n",
            "s=input(\"enter a string: \")\n",
            "dig=dig(s.split(' '))\n",
            "\n",
            "for i in s:\n",
            "    if(i==dig):\n",
            "       break\n",
            "\n",
            "print(f'dig: {s}')\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  2,231. Loss: 0.08538360148668289.   Elapsed: 0:15:50.\n",
            "0:  triple# write a python function to convert a list of dictionaries to lists and return the list of values\n",
            " | def convert_list_to_values(list_of_values):\n",
            "   return list([1, 2, 1, 3, 3, 1, 4, 1, 2, 1]\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  2,231. Loss: 0.12654007971286774.   Elapsed: 0:16:40.\n",
            "0: 220# write a python function to remove empty list from a list of lists using filter function.\n",
            " | \n",
            "def remove_emptylist(list_of_list_list:list_of_list_list):\n",
            "    return filter(lambda ele: ele[::-1]) == filter(lambda ele: ele[::-1]) == filter(lambda ele: ele[::-1]) == filter(lambda ele: ele[::-1]) == filter(lambda ele: ele[::-1]) == list_of_list_list_list_list_list_list.\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  2,231. Loss: 0.03334340825676918.   Elapsed: 0:17:30.\n",
            "0:  See# write a python program to implement binary search without recursion and print the key element if found\n",
            " | \n",
            "def binary_search(alist, key):\n",
            "    \"\"\"search key in alist. \"\"\"\n",
            "    if key in alist:\n",
            "        return key\n",
            " \n",
            "alist = [2, 3, 5, 6, 7, 8]\n",
            "\n",
            "if not alist:\n",
            "    print('[0-9-1-1]', end='')\n",
            "else:\n",
            "     print('[0-5-1]', end='')\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  2,231. Loss: 0.0835384801030159.   Elapsed: 0:18:21.\n",
            "0: @@# write a python function to remove tuples of length k  \n",
            " | def remove_tuple_(test_list:list): \n",
            "    t = list(test_list.strip()): \n",
            "    return t \n",
            "   \n",
            "    \n",
            "    if len(test_list) == k : \n",
            "       return (test_list.strip().split(' ')) \n",
            "    \n",
            "    t = list(test_list.strip().split(' ')) \n",
            "    return t  \n",
            "     \n",
            "   else: \n",
            "      raise valueerror('invalid input')\n",
            "\n",
            "\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epoch took: 0:18:38\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:39\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  2,231. Loss: 0.026105130091309547.   Elapsed: 0:00:49.\n",
            "0:  host# write a python function to calculate lcm\n",
            " | def compute_lcm(x, y):\n",
            "   if x > y:\n",
            "      greater = x\n",
            "   else:\n",
            "      greater = y\n",
            "   while(true):\n",
            "      greater = greater/x\n",
            "      while(true):\n",
            "           if((greater % x == 0) and (greater % y == 0)):\n",
            "             lcm = greater\n",
            "           break\n",
            "     greater += 1\n",
            "\n",
            "    if((greater % x == 0) and (greater % y == 0)):\n",
            "       print(\"move disk 1 from left to right\", lcm)\n",
            "   else:\n",
            "   \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  2,231. Loss: 0.06244303286075592.   Elapsed: 0:01:41.\n",
            "0: role# write a python program to find time for current date and time\n",
            " |   \n",
            "current_date = datetime.strptime(current_date)\n",
            "print(current_date)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  2,231. Loss: 0.15324485301971436.   Elapsed: 0:02:31.\n",
            "0: iac# in[81]:\n",
            " | \n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  2,231. Loss: 0.09983811527490616.   Elapsed: 0:03:20.\n",
            "0:  LD# write a python program to get all possible permutations of '1,2,3,4,5,6,7,8'\n",
            " | def permute_prob(n):\n",
            "    permutations = []\n",
            "    for i in range(n):\n",
            "          permutations.append([])\n",
            "    return [permutations]\n",
            "\n",
            "\n",
            "print(perms)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  2,231. Loss: 0.06217159703373909.   Elapsed: 0:04:10.\n",
            "0:  Listen# write a python program to sort dictionary by key-value summation and print the sorted dictionary\n",
            " | def sort_dict_by_key_value(d:dict, key:dict):\n",
            "    key = lambda x:len(x)\n",
            "    value = key.value()\n",
            "d.sort_dict_by_key(d.dict, key.value()))\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  2,231. Loss: 0.22549283504486084.   Elapsed: 0:05:00.\n",
            "0:  dy# write a program to generate fibonacci series\n",
            " | n = 100\n",
            "a=[1,2,3]\n",
            "fibonacci series = a*b\n",
            "print(fibonacci series)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  2,231. Loss: 0.04656447097659111.   Elapsed: 0:05:50.\n",
            "0:  Domestic# write a python function to convert temperature  from fahrenheit to kelvin  \n",
            " |   \n",
            " def fahrenheit_to_kelvin(f): \n",
            "    if(f%3==0) and (f%4==0): \n",
            "       return (f%4)/5 \n",
            "    elif(f%3==0 and (f%4==0): \n",
            "       return (f%4)/5 \n",
            "    elif(f%4==0 and (f%4==0): \n",
            "        return (f%4)/5 \n",
            "    else: \n",
            "        return none\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  2,231. Loss: 0.05769640579819679.   Elapsed: 0:06:41.\n",
            "0:  beneficiaries# write a python program to print sum of natural numbers upto n, where n is an argument\n",
            " | n = 3\n",
            "\n",
            "print(n)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  2,231. Loss: 0.13832524418830872.   Elapsed: 0:07:31.\n",
            "0:  Title# write a python function to check if given string has at least one letter and one number\n",
            " | \n",
            "def check(string): \n",
            "    l = string[ : 10] \n",
            "    sum = 0\n",
            "     for i in range(0, len(l)): \n",
            "           sum += l[i] \n",
            "    return true \n",
            "print (check(string)) \n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  2,231. Loss: 0.05174819007515907.   Elapsed: 0:08:21.\n",
            "0:  μ# write a python function for dice roll asking user for input to continue and randomly give an output.\n",
            " | \n",
            "import random\n",
            "\n",
            "\n",
            "def dice():\n",
            "    from random import randint\n",
            "    randint = '11'\n",
            "    import random\n",
            "\n",
            "    import os\n",
            "\n",
            "     return random.randint(random.randint(2,10),2,4))\n",
            "\n",
            "def dice():\n",
            "    import random\n",
            "\n",
            "    pass\n",
            "\n",
            "print(\"rolling the dice...\")\n",
            "for i in range(4):\n",
            "    dices = []\n",
            "    for j in range(6):\n",
            "        sum = random.randint(random.randint(random.randint(2,5),2,7),2,4)\n",
            "                 dices.append(i)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  2,231. Loss: 0.05750125274062157.   Elapsed: 0:09:12.\n",
            "0:  selling# write a python function to find the uncommon words from two strings.\n",
            " | def uncommonwords(str1, str2):\n",
            "\tres_set = {}\n",
            "\tfor word in str1.split():\n",
            "\tres_set.update(word)\n",
            "\treturn res_set\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  2,231. Loss: 0.13776500523090363.   Elapsed: 0:10:02.\n",
            "0:  migrant# write a python program to add two integers without using the '+' operator in a list.\n",
            " | \n",
            "a=[2,3,4]\n",
            "b=2\n",
            "a+b=b\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  2,231. Loss: 0.07170932739973068.   Elapsed: 0:10:52.\n",
            "0: ively# write a python function to find the greatest common divisor (gcd) of two integers.\n",
            " | def recurgcd(a, b):\n",
            "   if b == 0:\n",
            "      return (a % b % a)\n",
            "   else:\n",
            "      return none\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  2,231. Loss: 0.07175075262784958.   Elapsed: 0:11:42.\n",
            "0:  order# write a function to return the volume of a cuboid of length l, bredth b, height h\n",
            " | def cal_cuboid_volume(l,b,h):\n",
            "    return l*b*b\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  2,231. Loss: 0.07811251282691956.   Elapsed: 0:12:32.\n",
            "0:  VPN#write a python program to print binary search without recursion\n",
            " | \n",
            "def bin_search(alist):\n",
            "    \"\"\"search key in alist[start... end - 1].\"\"\"\n",
            "    for j in range(1, len(alist)):\n",
            "         alist[j], alist[start... end - 1] = alist[j], alist[j]\n",
            "               index = j - 1\n",
            "             for j in range(i+1):\n",
            "                  if alist[j + 1] < alist[j]:\n",
            "                                alist\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  2,231. Loss: 0.11945264786481857.   Elapsed: 0:13:23.\n",
            "0:  explanation# given a sorted integer array without duplicates, return the summary of its ranges.\n",
            " | input_array = [0]*(1)**len(input_array)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  2,231. Loss: 0.04063468426465988.   Elapsed: 0:14:13.\n",
            "0:  Bach# write a python program that asks user for input to make a simple equation\n",
            " | \n",
            "a = 1\n",
            "b = float('inf'), float('inf')\n",
            "a_diff = -b\n",
            "b_diff = -a- b\n",
            "if a_diff >= 0:\n",
            "    print(\"enter a number:\", end=\" \")\n",
            "else:\n",
            "    print(\"in a positive range:\", end=\" \")\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  2,231. Loss: 0.027624232694506645.   Elapsed: 0:15:03.\n",
            "0:  folder# printing result  \n",
            " | print(\"incremented numeric strings : \" + str(res))\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,900  of  2,231. Loss: 0.02472463622689247.   Elapsed: 0:15:53.\n",
            "0:  building# write a python program to add an element to a list\n",
            " | \n",
            "list1 = [10, 20, 30, 40, 50]\n",
            "list2 = list1 + list2 \n",
            "\n",
            "print(list2)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,000  of  2,231. Loss: 0.05709148570895195.   Elapsed: 0:16:42.\n",
            "0:  Babylon# write a python function that takes a number of lines as input and counts the number of each line\n",
            " | def count_lines(lines):\n",
            "    return len(lines)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,100  of  2,231. Loss: 0.10731413215398788.   Elapsed: 0:17:32.\n",
            "0: perial# write a program to convert binary to gray code\n",
            " | def binary_to_gray(n):\n",
            "    \"\"\"convert binary to gray codeword and return it.\"\"\"\n",
            "    if n == 0:\n",
            "        return bin(n)[::-1] + (n >> 2) + n[::-1])\n",
            "    else:\n",
            "       return (convert(n)[::-1]) + n[::-1])\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 2,200  of  2,231. Loss: 0.053033217787742615.   Elapsed: 0:18:23.\n",
            "0:  rents# write a function to calculate the average time taken to perform any transaction by  function fn averaging the total time taken for transaction over repetations\n",
            " | def time_it(fn, *args, repetitons= 1, **kwargs):\n",
            "    import time\n",
            "    total_time = time.perf_counter()\n",
            "    if __name__ == \"__main__\":\n",
            "         total_time = []\n",
            "    for _ in range(repetitons):\n",
            "         time.append(time.strftime('%y-%m-%d %h:%m:%s')\n",
            "         total_time.append(_)\n",
            "     else:\n",
            "          total_time.append(time.strftime('%y-%m-%\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epoch took: 0:18:40\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:39\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  2,231. Loss: 0.026908645406365395.   Elapsed: 0:00:49.\n",
            "0:  Reg# write a python program to extract tuples of length 1 from a list of tuples. print the extracted tuples.    \n",
            " |    \n",
            "test_list = [(4, 5, 9), (-3, 6, 10), (-3, 5, 3), (-3, 6), (4, 5, 7)] \n",
            "res = [(sub[1]: sub[1:]) for sub in test_list for key in test_list] \n",
            "  \n",
            "print(\"the extracted tuples : \" + str(res))\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  2,231. Loss: 0.06987442821264267.   Elapsed: 0:01:40.\n",
            "0: olas# write a python program to generate a list of all unique elements in a list\n",
            " | input = [1,2,3]\n",
            "samplelist = []\n",
            "for i in range(len(input)):\n",
            "   for j in range(len(input)-i-1):\n",
            "        if((i % j == 0) and (input[j]) == 0):\n",
            "            samplelist.append(input[j])\n",
            "print(samplelist)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  2,231. Loss: 0.027332797646522522.   Elapsed: 0:02:30.\n",
            "0:  responses# write a python program to print the binary value of a decimal number\n",
            " | dec = 344\n",
            "\n",
            "print(\"binary value of\", dec, \" is:\")\n",
            "print(binary(dec), \" is:\")\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  2,231. Loss: 0.11479006707668304.   Elapsed: 0:03:20.\n",
            "0:  attendance# write a python program to print a string in binary\n",
            " | print(\"yesterday = \", yesterday.strftime('%y-%d %h:%m:%p')\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  2,231. Loss: 0.06297052651643753.   Elapsed: 0:04:10.\n",
            "0:  rigid# write a python function that takes in a string and returns it in lowercase\n",
            " | def print_lower(s):\n",
            "  return s.lower()\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  2,231. Loss: 0.07158723473548889.   Elapsed: 0:04:59.\n",
            "0: gro# write a python program that adds elements of two lists\n",
            " | \n",
            "list1 = [1, 2, 3, 4]\n",
            "list2 = [5, 4, 3, 2, 1]\n",
            "sum_list = [a+b for a,b in zip(list1, list2)]\n",
            "print(f\"sum of two lists:{sum_list}\")\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  2,231. Loss: 0.08140068501234055.   Elapsed: 0:05:49.\n",
            "0:  Gre# iterate through rows\n",
            " | for i in range(len(x)):\n",
            "  # iterate through columns\n",
            "   for j in range(len(x[0])):\n",
            "      result[j][i] = x[i][j]\n",
            "\n",
            "for r in result:\n",
            "  print(r)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  2,231. Loss: 0.11563535034656525.   Elapsed: 0:06:40.\n",
            "0: ura# generate  random number between 2 ranges\n",
            " | import random\n",
            "\n",
            "lower, upper = 2,5\n",
            "number = random.randint(lower, upper)\n",
            "print(\"generating a random number between\", number, \"and\", its cube)\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  2,231. Loss: 0.047015152871608734.   Elapsed: 0:07:29.\n",
            "0:  2020# write a function to return the lateral surface area of a cylinder\n",
            " | def cal_cylinder_lat_surf_area(height,radius):\n",
            "    pi=3.14\n",
            "    return 2*pi*radius*height\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  2,231. Loss: 0.07454726845026016.   Elapsed: 0:08:19.\n",
            "0:  charging# write a python program to check if a number is a perfect number\n",
            " | \n",
            "def perfect_no_check(num):\n",
            "    sum1 = 0\n",
            "    for i in range(1,num + 1):\n",
            "        sum1 = sum1 + i\n",
            "    return sum1\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  2,231. Loss: 0.027883952483534813.   Elapsed: 0:09:09.\n",
            "0:  Sar# write a python function to calculate the geometric sum of the squares of the first two hundred natural numbers, if the square of the first two hundred is an even number, divide it by a given mean and standard deviation\n",
            " | def geometric_sum(x, y):\n",
            "    e = 0\n",
            "    while x**2 and y**2< e:\n",
            "        e += 1\n",
            "        y += 1\n",
            "    return e\n",
            "\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  2,231. Loss: 0.058623313903808594.   Elapsed: 0:09:59.\n",
            "0:  Jas# write a python function to check if a triangle is valid for all angles\n",
            " | \n",
            "def all_validity(a, b):\n",
            "    return all(a+b for a,b in (a+b+c))\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,300  of  2,231. Loss: 0.018667297437787056.   Elapsed: 0:10:49.\n",
            "0:  permit# write a python function to print the factorial of a number\n",
            " | def factorial(n):\n",
            "    if n == 1:\n",
            "         return n\n",
            "    else:\n",
            "         return n * factorial(n-1)\n",
            "\n",
            "factorial(7)\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,400  of  2,231. Loss: 0.17547450959682465.   Elapsed: 0:11:39.\n",
            "0:  Administrator# write a python program to remove common elements from tuple list\n",
            " | from collections import counter\n",
            "l=[[1,2,3], [4,5,6], [7,8,9]]\n",
            "t=tuple(l)\n",
            "print(l)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,500  of  2,231. Loss: 0.059273749589920044.   Elapsed: 0:12:29.\n",
            "0:  EVENTS# write a python program to check whether a number is positive, negative or zero\n",
            " | num = 175\n",
            "if num > 0:\n",
            "   print(\"positive number\")\n",
            "elif num == 0:\n",
            "   print(\"zero\")\n",
            "else:\n",
            "   print(\"negative number\")\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,600  of  2,231. Loss: 0.05363699048757553.   Elapsed: 0:13:19.\n",
            "0:  Mental# write a python function that accepts an integer as input and converts it into a string\n",
            " | def convertstring(n):\n",
            "    n = int(n, 2)\n",
            "    return ''.join(str(n))\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,700  of  2,231. Loss: 0.060534123331308365.   Elapsed: 0:14:09.\n",
            "0: ids# write a python function that accepts a list of dictionaries and sorts it by a specified key\n",
            " | \n",
            "def sort_dict_list(dict_list, sort_key):\n",
            "  dict_list.sort(key=lambda x: (-x[1]//k) + key[1])\n",
            "\n",
            "print(sort_dict_list)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,800  of  2,231. Loss: 0.051640406250953674.   Elapsed: 0:14:59.\n",
            "0: ceans# write a program to randomly generate a list with 5 numbers, which are divisible by 5 and 7, between 1 and 1000 inclusive.\n",
            " | import random\n",
            "print(random.sample([i for i in range(1,1001) if i%5==0 and i%7==0], 5))\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1,900  of  2,231. Loss: 0.06254614144563675.   Elapsed: 0:15:49.\n",
            "0:  genetically# write a python program to extract words starting with vowel from a list of strings\n",
            " | \n",
            "s = ['a', 'e', 'i', 'o', 'u']\n",
            "k = 2\n",
            "res = [] \n",
            "vow = ['a', 'e', 'i', 'o', 'u']\n",
            "for v in s: \n",
            "    if v not in vow: \n",
            "        res.append(v)\n",
            "\n",
            "print(\"words starting with vowel : \" + str(res))\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,000  of  2,231. Loss: 0.05196220427751541.   Elapsed: 0:16:39.\n",
            "0:  advice# write a python function that returns true if the sum of two provided numbers is even\n",
            " | def is_prod_even(num1, num2):\n",
            "  sum = num1 + num2\n",
            "  return not sum % 2\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,100  of  2,231. Loss: 0.030109701678156853.   Elapsed: 0:17:29.\n",
            "0:  incomplete# iterate through rows of x\n",
            " | for i in range(len(x)):\n",
            "   # iterate through columns of y\n",
            "   for j in range(len(y[0])):\n",
            "       # iterate through rows of y\n",
            "       for k in range(len(y)):\n",
            "           result[i][j] += x[i][k] * y[k][j]\n",
            "print(f\"final result is{result}\")\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2,200  of  2,231. Loss: 0.02070428617298603.   Elapsed: 0:18:20.\n",
            "0: comment# printing original dictionary \n",
            " | print(\"the original dictionary is : \" + str(test_dict)) \n",
            "s=[]\n",
            "for sub in test_dict.items():\n",
            "    s.append(str(sub.get))\n",
            "print(s) \n",
            "\n",
            "\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epoch took: 0:18:35\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:39\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:36:34 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "2dvUlZcgOrNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "H-6GRs5eOwMQ",
        "outputId": "3efedd76-3d21-42b9-eacc-fa475436e1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss Training Time Validation Time\n",
              "epoch                                                          \n",
              "1               0.26         0.15       0:18:48         0:00:39\n",
              "2               0.14         0.13       0:18:40         0:00:39\n",
              "3               0.11         0.12       0:18:38         0:00:39\n",
              "4               0.08         0.10       0:18:40         0:00:39\n",
              "5               0.05         0.10       0:18:35         0:00:39"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94bd3600-9e12-409e-9edf-db9b9761d5b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.26</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0:18:48</td>\n",
              "      <td>0:00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0:18:40</td>\n",
              "      <td>0:00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0:18:38</td>\n",
              "      <td>0:00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.08</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0:18:40</td>\n",
              "      <td>0:00:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0:18:35</td>\n",
              "      <td>0:00:39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94bd3600-9e12-409e-9edf-db9b9761d5b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94bd3600-9e12-409e-9edf-db9b9761d5b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94bd3600-9e12-409e-9edf-db9b9761d5b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "aFYCjD1dO08C",
        "outputId": "07b822a7-d552-4100-9a57-f37f9ee0aa16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode('<SOS>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Zwmgga-XOT",
        "outputId": "07b4395a-e88b-4ce2-ffa7-e6584bc1a72d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50257]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"<SOS> # write a function that sums two integers | \"\n",
        "\n",
        "encoding = tokenizer(prompt)#, truncation = True, padding = \"max_length\")\n",
        "input_ids = torch.tensor(encoding['input_ids']).to(device).unsqueeze(0)\n",
        "attention_mask = torch.tensor(encoding['attention_mask']).to(device).unsqueeze(0)\n",
        "\n",
        "bos = torch.tensor(tokenizer.encode('<SOS>')).to(device)\n",
        "eos = torch.tensor(tokenizer.encode('<EOS>')).to(device)\n",
        "pad = torch.tensor(tokenizer.encode('<PAD>')).to(device)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                input_ids = input_ids,\n",
        "                                attention_mask = attention_mask, \n",
        "                                bos_token_id=bos,\n",
        "                                eos_token_id=eos,\n",
        "                                pad_token_id=pad,\n",
        "                                do_sample=True,   \n",
        "                                top_k=50, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-pTr8gA-7i8",
        "outputId": "2c42c9fc-ab99-4934-b54d-98d690d40ace"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  # write a function that sums two integers |         \n",
            "              \n",
            "      \n",
            "      \n",
            "      \n",
            "       \n",
            "    \n",
            "       \n",
            "      \n",
            "          \n",
            "       \n",
            "     \n",
            "        \n",
            "         \n",
            "         \n",
            "         \n",
            "        \n",
            "    \n",
            "      \n",
            "           \n",
            "      \n",
            "             \n",
            "         \n",
            "       \n",
            "         \n",
            "           \n",
            "                        \n",
            "             \n",
            "        \n",
            "          \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "prompt = \"<SOS> # write a function that sorts a list | \"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated, \n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,   \n",
        "                                top_k=25, \n",
        "                                max_length = 300,\n",
        "                                top_p=0.95, \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UgD8q61PJ7L",
        "outputId": "459ef4b7-a863-4c5c-b3b9-6a2cd275dd6f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50257,     2,  3551,   257,  2163,   326, 10524,   257,  1351,   930,\n",
            "           220]], device='cuda:0')\n",
            "0: # write a function that sorts a list | --------------------------- print a list of integers and integers\n",
            "# print the list of integers and integers\n",
            "# print the list of integers and integers\n",
            "# print the list of integers and integers\n",
            "# print the list of integers and integers\n",
            "# print the list\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JN-IrYAqlhAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}